{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/poc_data/data.zip /content"
      ],
      "metadata": {
        "id": "k_DJs0b0XmYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/data.zip\n",
        "!clear\n",
        "!rm /content/data.zip"
      ],
      "metadata": {
        "id": "kFESjjUcXy0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/data /content"
      ],
      "metadata": {
        "id": "Z5EzWyhIQo7Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZWkzidvi2K2",
        "outputId": "abfc00b8-4e0b-4bb5-dce3-16dd2623f9d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 22 04:15:29 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    44W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']"
      ],
      "metadata": {
        "id": "e3JMjCVre_ik"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl --force-reinstall "
      ],
      "metadata": {
        "id": "4cmFCXK6foWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a80c3a-a14e-4429-e761-d76c9642c031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-xla==1.12\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl (393.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 393.5 MB 46 kB/s \n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting torch==1.12.0\n",
            "  Downloading torch-1.12.0-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.3 MB 19 kB/s \n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 90.6 MB/s \n",
            "\u001b[?25hCollecting oauth2client\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting google-auth-httplib2>=0.0.3\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting google-auth>=1.4.1\n",
            "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 70.9 MB/s \n",
            "\u001b[?25hCollecting google-api-core<2dev,>=1.13.0\n",
            "  Downloading google_api_core-1.33.2-py3-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 71.2 MB/s \n",
            "\u001b[?25hCollecting six<2dev,>=1.6.1\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting httplib2<1dev,>=0.9.2\n",
            "  Downloading httplib2-0.21.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting uritemplate<4dev,>=3.0.0\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 94.8 MB/s \n",
            "\u001b[?25hCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5\n",
            "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 83.8 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 87.1 MB/s \n",
            "\u001b[?25hCollecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 95.6 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 94.6 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 135 kB/s \n",
            "\u001b[?25hInstalling collected packages: pyasn1, urllib3, six, rsa, pyparsing, pyasn1-modules, protobuf, idna, charset-normalizer, certifi, cachetools, requests, httplib2, googleapis-common-protos, google-auth, uritemplate, google-auth-httplib2, google-api-core, oauth2client, google-api-python-client, typing-extensions, cloud-tpu-client, absl-py, torch-xla, torch\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.4.8\n",
            "    Uninstalling pyasn1-0.4.8:\n",
            "      Successfully uninstalled pyasn1-0.4.8\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1-modules 0.2.8\n",
            "    Uninstalling pyasn1-modules-0.2.8:\n",
            "      Successfully uninstalled pyasn1-modules-0.2.8\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.1.1\n",
            "    Uninstalling charset-normalizer-2.1.1:\n",
            "      Successfully uninstalled charset-normalizer-2.1.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.2.0\n",
            "    Uninstalling cachetools-5.2.0:\n",
            "      Successfully uninstalled cachetools-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.57.0\n",
            "    Uninstalling googleapis-common-protos-1.57.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.57.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.14.1\n",
            "    Uninstalling google-auth-2.14.1:\n",
            "      Successfully uninstalled google-auth-2.14.1\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 3.0.1\n",
            "    Uninstalling uritemplate-3.0.1:\n",
            "      Successfully uninstalled uritemplate-3.0.1\n",
            "  Attempting uninstall: google-auth-httplib2\n",
            "    Found existing installation: google-auth-httplib2 0.0.4\n",
            "    Uninstalling google-auth-httplib2-0.0.4:\n",
            "      Successfully uninstalled google-auth-httplib2-0.0.4\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.8.2\n",
            "    Uninstalling google-api-core-2.8.2:\n",
            "      Successfully uninstalled google-api-core-2.8.2\n",
            "  Attempting uninstall: oauth2client\n",
            "    Found existing installation: oauth2client 4.1.3\n",
            "    Uninstalling oauth2client-4.1.3:\n",
            "      Successfully uninstalled oauth2client-4.1.3\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.11\n",
            "    Uninstalling google-api-python-client-1.12.11:\n",
            "      Successfully uninstalled google-api-python-client-1.12.11\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cloud-tpu-client==0.10 torch==1.10.0 torchvision==0.11.1 torchaudio==0.10.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "PHXaJioAE7Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q torchaudio==0.12.0 -f https://download.pytorch.org/whl/cu111/torch_stable.html  \n",
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfGx_bSFzMXn",
        "outputId": "8c101881-22b7-4ec3-ccdb-dc6ff19888f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "-TOUtN7VcarR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.randn(2, 2, device=xm.xla_device())\n",
        "print(t.device)\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azfT-04SgbdR",
        "outputId": "8a5ca654-f60d-47a5-b059-306866c37b31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xla:1\n",
            "tensor([[-0.6989, -0.0987],\n",
            "        [ 0.7337, -0.9071]], device='xla:1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ASR Model"
      ],
      "metadata": {
        "id": "IFwzs0YFzAaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchaudio\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "xVc2EboYzIeP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('model diye jachi')\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        print('model diye ekhono jachi')\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "DoGvtvyhzADt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning"
      ],
      "metadata": {
        "id": "1DjgMjpBG23O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextTransform:\n",
        "    \"\"\"Maps phonemes to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        self.url = \"https://dev.revesoft.com:6790/phonemizer\"\n",
        "        self.headers = {\n",
        "                        'Content-Type': 'application/json'\n",
        "                        }\n",
        "        self.phonome_map_str = \"\"\"\n",
        "                                a 1\n",
        "                                ã 2\n",
        "                                b 3\n",
        "                                bʰ 4\n",
        "                                c 5\n",
        "                                cʰ 6\n",
        "                                d 7\n",
        "                                dʰ 8\n",
        "                                d̪ 9\n",
        "                                d̪ʰ 10\n",
        "                                e 11\n",
        "                                ẽ 12\n",
        "                                g 13\n",
        "                                gʰ 14\n",
        "                                h 15\n",
        "                                i 16\n",
        "                                ĩ 17\n",
        "                                i̯ 18\n",
        "                                k 19\n",
        "                                kʰ 20\n",
        "                                l 21\n",
        "                                m 22\n",
        "                                n 23\n",
        "                                o 24\n",
        "                                õ 25\n",
        "                                o̯ 26\n",
        "                                p 27\n",
        "                                pʰ 28\n",
        "                                r 29\n",
        "                                s 30\n",
        "                                t 31\n",
        "                                tʰ 32\n",
        "                                t̪ 33\n",
        "                                t̪ʰ 34\n",
        "                                u 35\n",
        "                                ũ 36\n",
        "                                u̯ 37\n",
        "                                æ 38\n",
        "                                æ̃ 39\n",
        "                                ŋ 40\n",
        "                                ɔ 41\n",
        "                                ɔ̃ 42\n",
        "                                ɟ 43\n",
        "                                ɟʰ 44\n",
        "                                ɽ 45\n",
        "                                ɽʰ 46\n",
        "                                ʃ 47\n",
        "                                ʲ 48\n",
        "                                ʷ 49\n",
        "                                \n",
        "                                \"\"\"\n",
        "        self.phone_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in self.phonome_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.phone_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[50] = '@'\n",
        "        self.phone_map['@'] = 50\n",
        "        \n",
        "    \n",
        "    def remove_punctuations(self, text):\n",
        "        # define punctuation\n",
        "        regex = r\"[!\\\"#\\$%।\\'\\(\\)\\*\\+,-\\./:‘’;<=>\\?@\\[\\\\\\]\\^_`{\\|}~]\"\n",
        "        \n",
        "        subst = \"\"\n",
        "\n",
        "        result = re.sub(regex, subst, text, 0, re.MULTILINE)\n",
        "        return result\n",
        "    \n",
        "    def remove_english_letters_and_numbers(self, text):\n",
        "        return re.sub(r'[A-Za-z0-9]+[ \\t]*', r'', text)\n",
        "        \n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        # print(text)\n",
        "        text = self.remove_english_letters_and_numbers(text)\n",
        "        text = self.remove_punctuations(text)\n",
        "        \n",
        "        payload = json.dumps({\n",
        "                            \"text\": text\n",
        "                            })\n",
        "        \n",
        "        requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
        "        response = requests.request(\"POST\", self.url, headers=self.headers, data=payload, verify=False)\n",
        "        phone_list = response.json()['output']\n",
        "          \n",
        "        print(phone_list)\n",
        "        int_sequence = []\n",
        "        for phone_per_word in phone_list:\n",
        "            phone_per_word = phone_per_word.replace(\"_1\", \"\")\n",
        "            phone_per_word = phone_per_word.replace(\"-\", \"\")\n",
        "            phone_per_word = phone_per_word.replace(\"_2\", \"\")\n",
        "            phone = \"\"\n",
        "            for i in range(len(phone_per_word)):\n",
        "                if i == len(phone_per_word) - 1:\n",
        "                    phone += phone_per_word[i]\n",
        "                    # print(phone)\n",
        "                        # exit()\n",
        "                    ch = self.phone_map[phone]\n",
        "                    int_sequence.append(ch)\n",
        "                elif phone_per_word[i] != \" \":\n",
        "                    phone += phone_per_word[i]\n",
        "                else:\n",
        "                    ch = self.phone_map[phone]\n",
        "                    int_sequence.append(ch)\n",
        "                    phone = \"\"\n",
        "            int_sequence.append(self.phone_map['@'])\n",
        "        \n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('', ' ')\n"
      ],
      "metadata": {
        "id": "SuR0JCUEiY3T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = TextTransform()\n",
        "int_seq = demo.text_to_int('যুক্তরাষ্ট্র ও রাশিয়ার মধ্যে নতুন START8,2,234,, frOm Th চুক্তির ভবিষ্যৎ নিয়েও কিছু বলবেন আশা করি')\n",
        "print(int_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD1B0LZFZILr",
        "outputId": "4603e021-e9f5-4a5c-bfcd-9e73a4067475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[43, 35, 19, 33, 24, 29, 1, 47, 31, 29, 24, 50, 24, 50, 29, 1, 47, 16, 48, 1, 29, 50, 22, 24, 9, 10, 11, 50, 23, 24, 33, 35, 23, 50, 5, 35, 19, 33, 16, 29, 50, 4, 24, 3, 16, 47, 47, 41, 33, 50, 23, 16, 48, 11, 26, 50, 19, 16, 6, 35, 50, 3, 24, 21, 3, 11, 23, 50, 1, 47, 1, 50, 19, 24, 29, 16, 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "bBDgWNjKHTTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchaudio\n",
        "import glob\n",
        "import csv\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "_kOe4A8GHSBs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BanglaData(Dataset):\n",
        "    \n",
        "    def __init__(self, data_folder: str = '/content/data'):\n",
        "        \n",
        "        self.audio_file_paths = glob.glob(data_folder+'/**/**/*.wav')\n",
        "        self.text_file_paths = glob.glob(data_folder+'/**/**/*.txt')\n",
        "    \n",
        "    def load_item(self, n: int) -> Tuple[Tensor, int, str]:\n",
        "        audio_path = self.audio_file_paths[n]\n",
        "        text_path = self.text_file_paths[n]\n",
        "        # Load audio\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        # Load text\n",
        "        utterance = '। '.join(open(text_path, 'r', encoding='utf-8').readlines())\n",
        "        # print(len(utterance))\n",
        "        \n",
        "        return (\n",
        "            waveform,\n",
        "            sample_rate,\n",
        "            utterance,\n",
        "        )\n",
        "    \n",
        "    def __getitem__(self, n: int) -> Tuple[Tensor, int, str]:\n",
        "        \n",
        "        return self.load_item(n)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.audio_file_paths)\n"
      ],
      "metadata": {
        "id": "s2UAoUYNG0s-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# import asr_model\n",
        "# import mlflow\n",
        "# import mlflow.pytorch\n",
        "\n",
        "# from dataset import BanglaData\n",
        "from platform import python_branch\n",
        "# from data_utils import TextTransform\n",
        "from cmath import nan\n",
        "from torch import nn\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "phone_cache = {} "
      ],
      "metadata": {
        "id": "sUj-D-StH5JQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckp(state, checkpoint_dir = './saved_model'):\n",
        "    f_path = checkpoint_dir + '/best_model_checkpoint.pt'\n",
        "    torch.save(state, f_path)\n",
        "\n",
        "def data_processing(train_audio_transforms, valid_audio_transforms,text_transform, data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        spectrograms.append(spec)\n",
        "        \n",
        "        \n",
        "        # if phone_cache.get(utterance) is not None:\n",
        "        if utterance not in phone_cache.keys():\n",
        "            phone_cache[utterance] = torch.Tensor(text_transform.text_to_int(utterance))\n",
        "            label = phone_cache[utterance]\n",
        "        else:\n",
        "            label = phone_cache[utterance]\n",
        "            \n",
        "        # label = torch.Tensor(text_transform.text_to_int(utterance))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "def train(model, device, train_loader, test_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    count_train = 0\n",
        "    tot_train_loss = []\n",
        "    batch_count = 1\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        print('batch: ', batch_count)\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(spectrograms)  # (batch, time, n_class)\n",
        "        print('output paisi')\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        print('output process kortesi', output.shape)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "        print('output process kortesi')\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        print('output process kortesi', loss)\n",
        "        tot_train_loss.append(loss.item())\n",
        "        if loss == nan:\n",
        "            print('loss for this batch is NaN')\n",
        "        loss.backward()\n",
        "        print('output process kortesi')\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        print('output process kortesi nice')\n",
        "        count_train += 1\n",
        "        batch_count += 1\n",
        "        print('notun batch dao')\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    \n",
        "    model.eval()\n",
        "    tot_val_loss = []\n",
        "    count_val = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, _data in enumerate(test_loader):\n",
        "            print('validation hoche')\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            count_val += 1\n",
        "            tot_val_loss.append(loss.item())\n",
        "    \n",
        "           \n",
        "    return float(sum(tot_val_loss)/count_val), model, optimizer\n",
        "    \n",
        "\n",
        "\n",
        "def main(train_audio_transforms, valid_audio_transforms, text_transform, learning_rate=5e-4, batch_size=20, epochs=10, device = 'cuda'):\n",
        "\n",
        "    # model config for training with smaller dataset(backup_data) \n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 51,\n",
        "        \"n_feats\": 80,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    # model config for training with larger dataset(all_data) \n",
        "    # hparams = {\n",
        "    #     \"n_cnn_layers\": 5,\n",
        "    #     \"n_rnn_layers\": 7,\n",
        "    #     \"rnn_dim\": 512,\n",
        "    #     \"n_class\": 51,\n",
        "    #     \"n_feats\": 80,\n",
        "    #     \"stride\":2,\n",
        "    #     \"dropout\": 0.1,\n",
        "    #     \"learning_rate\": learning_rate,\n",
        "    #     \"batch_size\": batch_size,\n",
        "    #     \"epochs\": epochs\n",
        "    # }\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    # device = torch.device(\"cuda:1\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "    train_dataset = BanglaData(data_folder = '/content/data/train')\n",
        "    test_dataset = BanglaData(data_folder = '/content/data/valid')\n",
        "    \n",
        "    # kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(train_audio_transforms, valid_audio_transforms, text_transform, x, 'train'))\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(train_audio_transforms, valid_audio_transforms, text_transform, x, 'valid'))\n",
        "    # for __data in train_loader:\n",
        "    #     print(__data)\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "    # print(model)\n",
        "    # print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=0, zero_infinity=True).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "\n",
        "    \n",
        "    best_loss = 100000000000000000\n",
        "    path = './saved_model'\n",
        "    save_path = os.path.join(path,'phoneme_prediction_model.pt')\n",
        "    isExist = os.path.exists(path)\n",
        "    if not isExist:\n",
        "        os.makedirs(path)\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print('epoch: ', epoch)\n",
        "        temp_loss, model, optimizer = train(model, device, train_loader, test_loader, criterion, optimizer, scheduler, epoch)\n",
        "        print('epoch: ', epoch, ' complete')\n",
        "        if temp_loss < best_loss:\n",
        "            checkpoint = {\n",
        "                        'epoch': epoch,\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict()\n",
        "                        }\n",
        "            print(f'validation loss decreased from {best_loss} to {temp_loss}, model being saved')\n",
        "            best_loss = temp_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            save_ckp(checkpoint)\n"
      ],
      "metadata": {
        "id": "va-hr-4sHXyN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, n_mels=80),\n",
        "    # torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=80),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, n_mels=80)\n",
        "# valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=80),\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "learning_rate = 2e-5\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "start = time.time()\n",
        "main(train_audio_transforms, valid_audio_transforms, text_transform, learning_rate, batch_size, epochs)\n",
        "end = time.time()\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3o7jGwoVxPr",
        "outputId": "0e3f4ed2-0fc3-4920-c44f-3d8275c5fc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1\n",
            "['e_1 r_2', 'b_1 a i̯ r e_2', 'ɟ_1 e l a ʲ_2', 'b_1 æ p o k_2', 'a_1 k a r e_2', 't̪_1 o i̯ r i_2', 'p_1 o ʃ a k_2', 's_1 r o m i k ʃ ɔ h o_2', 'o_1 n n æ n n o_2', 'ʃ_1 r o m i k r a_2', 'r_1 o ʲ e cʰ e_2']\n",
            "['p_1 u l i ʃ e r_2', 'p_1 o ʃ a k d̪ʰ a r i_2', 'c_1 ɔ o̯ ɽ a_2', 'g_1 õ pʰ o ʷ a l a_2', 'l_1 o k t i k e_2', 'r_1 u p k ɔ t̪ʰ a r_2', 'ɟ_1 ɔ l l a d̪ e r_2', 'm_1 ɔ t̪ o i̯_2', 'd̪_1 æ kʰ a c cʰ i l o_2']\n",
            "['n_1 a m_2', 'n_1 a_2', 'ɟ_1 a n a_2', 'k_1 ɔ t̪ o_2', 'g_1 a cʰ_2', 'p_1 ɔ t̪ʰ e r_2', 'd̪_1 u p a ʃ e_2']\n",
            "['k_1 i cʰ u t a_2', 'h_1 ã pʰ_2', 'cʰ_1 e ɽ e_2', 'b_1 a c l a m_2']\n",
            "['æ_1 g a r o_2', 'd̪_1 ɔ pʰ a_2', 'ɟ_1 o u̯ k t̪ i k_2', 'd̪_1 a b i t̪ e_2', 'a_1 m a d̪ e r_2', 'a_1 ɟ k e r_2', 'e_1 i̯_2', 'a_1 n d̪ o l o n_2']\n",
            "['t̪_1 a r_2', 'm_1 a_2', 'e_1 ʃ e cʰ i l e n_2', 'e', 'b_1 i ʃ ɔ ʲ e_2', 'k_1 ɔ t̪ʰ a_2', 'b_1 o l t̪ e_2']\n",
            "['a_1 r o_2', 'k_1 ɔ t̪ o_2', 'k_1 i_2']\n",
            "['g_1 r a m a n c o l e_2', 'p_1 u r b e r_2', 'ʃ_1 ɔ b_2', 'ʃ_1 u d̪ kʰ o r_2', 'ɟ_1 o t̪ d̪ a r d̪ e r_2', 't̪_1 u l o n a ʲ_2', 'e_1 n ɟ i o g u l o_2', 'a_1 r o_2', 'k_1 ɔ ʲ e k_2', 'g_1 u n_2', 'u_1 p o r e_2']\n",
            "['a_1 b a r_2', 'ɔ_1 n e k_2', 'ʃ_1 o m ɔ ʲ_2', 'bʰ_1 e b e cʰ e_2', 'e', 'p_1 ɔ t̪ʰ e_2', 'a_1 r_2', 'n_1 a_2']\n",
            "['o_1 n n o d̪ e r_2', 'm_1 o d̪ d̪ʰ e_2', 's_1 t æ m pʰ o r d_2', 'i_1 u̯ n i bʰ a r s i t i_2', 'b_1 a ŋ l a d̪ e ʃ e r_2', 'u_1 p a c a r ɟ o_2', 'o_1 d̪ d̪ʰ a p ɔ k_2', 'm_1 o h a m m ɔ d̪_2', 'a_1 l i_2', 'n_1 o k i_2']\n",
            "['æ_1 k t̪ r i ʃ_2', 'b_1 o l e_2', 't̪_1 a r_2', 'r_1 a n_2', 't̪_1 e t̪ a l l i ʃ_2']\n",
            "['t̪_1 a r_2', 'ɟ_1 o n n o i̯_2', 'ʃ_1 ɔ k o l_2', 'd̪_1 ɔ r ʃ o k_2', 'kʰ_1 æ l a r_2', 'a_1 n o n d̪ o_2', 'p_1 a ʲ_2']\n",
            "['b_1 ɔ ɽ o_2', 'b_1 o u̯_2', 'ɟ_1 i_2', 'a_1 m m a_2', 'b_1 o l e i̯_2', 'c_1 ɔ l e_2', 'g_1 e l e n_2']\n",
            "['kʰ_1 ɔ t t a_2', 'h_1 o l o_2', 'ʃ_1 ɔ ʲ ɔ n_2', 'k_1 ɔ r a r_2', 'kʰ_1 a t_2']\n",
            "['æ_1 kʰ o n_2', 't̪_1 a k e_2', 'a_1 m i_2', 'n_1 o t̪ u n_2', 'k_1 o r e_2', 'c_1 i n e_2', 'u_1 tʰ cʰ i_2']\n",
            "['e_1 ʃ ɔ b_2', 'k_1 i cʰ u_2', 'o_1 d̪ʰ i bʰ u k t̪ o_2', 'k_1 o n o_2', 'p_1 r o t̪ i ʃ tʰ a n e r_2', 'n_1 i ʲ o n t̪ r o n e r_2', 'b_1 a i̯ r e_2']\n",
            "['a_1 l a d̪ a_2', 's_1 a i̯ k e l_2', 'l_1 e i̯ n e r_2', 'b_1 æ b o s t̪ʰ a_2', 'k_1 ɔ r a_2']\n",
            "['n_1 i kʰ i l_2', 'b_1 i l e r_2', 'o_1 p a ʃ e_2', 'u_1 p o r e_2', 'n_1 i kʰ i l_2', 'a_1 k a ʃ_2']\n",
            "['a_1 b a r_2', 'a_1 ʃ e_2', 't̪_1 r a n_2']\n",
            "['r_1 i p a b l i k_2', 'g_1 r o n t̪ʰ e r_2', 'r_1 ɔ c o ʲ i t̪ a_2', 'p_1 l e t o_2']\n",
            "['u_1 c c a r o n_2', 'k_1 o r u n_2', 'ʃ_1 ɔ b d̪ o_2']\n",
            "['k_1 o u̯ ʃ o l l a r_2', 'k_1 o u̯ t a_2', 'n_1 i ʲ e_2', 'k_1 o u̯ t̪ u h o l i_2', 'm_1 a n u ʃ_2', 'k_1 o u̯ t̪ u k_2', 'k_1 ɔ r a_2', 'ʃ_1 u r u_2', 'k_1 o r l o_2']\n",
            "['t̪_1 i n i_2', 'ʃ_1 u t̪ o_2', 'b_1 o ɟʰ a ʲ_2', 'g_1 a cʰ t i r_2', 'd̪_1 i k e_2', 't̪_1 a k a n_2']\n",
            "['p_1 r a n i ɟ o_2', 'u_1 t̪ ʃ o l a k t o ɟ_2', 'b_1 a_2', 'd̪_1 u d̪ʰ_2', 'ʃ_1 ɔ r k k ɔ r a_2', 'g_1 o r u_2', 'cʰ_1 a g o l_2', 'e_1 b o ŋ_2', 'o_1 n n æ n n o_2', 'p_1 r a n i r_2', 'd̪_1 u d̪ʰ e_2', 'e_1 i̯_2', 'ʃ_1 ɔ r k k ɔ r a_2', 't̪ʰ_1 a k e_2']\n",
            "['t̪_1 i n i_2', 'k_1 o t̪ʰ a ʲ_2', 'ɟ_1 e n o_2', 'a_1 m a r_2', 's_1 r ĩ t̪ i r_2', 'g_1 o bʰ i r e_2', 'b_1 ẽ c e_2', 'a_1 cʰ e n_2']\n",
            "['n_1 i t̪ t̪ o d̪ i n e r_2', 'm_1 ɔ t̪ o_2', 'a_1 t̪ o r e r_2', 'ʃ_1 u r o bʰ i_2', 'm_1 a t̪ʰ a r_2', 'm_1 o d̪ d̪ʰ e_2', 'b_1 a ʃ a_2', 'b_1 ã d̪ʰ e_2']\n",
            "['ʃ_1 ɔ t̪ a b d̪ i r_2', 'p_1 r a n r a ŋ a_2', 'o_1 i̯ t̪ i ɟ ɟʰ o_2']\n",
            "['g_1 ɔ t̪ o_2', 'm_1 a ʃ e_2', 'æ_1 k_2', 'ʃ_1 ɔ ŋ b a d̪_2', 'b_1 i g g õ p t̪ i t̪ e_2', 'bʰ_1 a r o t̪_2', 'ʃ_1 ɔ r k a r_2', 'g_1 ɔ b e ʃ ɔ k d̪ e r_2', 'o_1 i̯_2', 'p_1 r o t̪ i b e d̪ o n k e_2', 'u_1 ɽ i ʲ e_2', 'd̪_1 i ʲ e cʰ e_2']\n",
            "['n_1 o t̪ u n_2', 'k_1 o r e_2', 'k_1 i_2', 'b_1 ɔ l a r_2', 'a_1 cʰ e_2']\n",
            "['n_1 i ʃ k r i ʲ o_2', 'k_1 o r u n_2', 'b_1 o m a t i_2']\n",
            "['ʃ_1 ɔ b ʃ o m ɔ ʲ_2', 'd̪_1 u r e_2', 'd̪_1 u r e_2', 't̪ʰ_1 a k i_2']\n",
            "['b_1 a b a r_2', 'b_1 o i̯ r a g g e r_2', 'ɔ_1 r t̪ t̪ʰ o h i n ɔ t̪ a_2', 'ʃ_1 ɔ k o l_2', 'p_1 r o t̪ i r o d̪ʰ_2', 'ʃ_1 ɔ t̪ t̪ e o̯_2', 't̪_1 a k e_2', 'ɔ_1 l i k_2', 'ʃ_1 ɔ n t̪ a n e r_2', 'd̪_1 i k e_2', 'tʰ_1 e l e_2', 'd̪_1 e ʲ_2']\n",
            "batch:  1\n",
            "model diye jachi\n",
            "model diye ekhono jachi\n",
            "output paisi\n",
            "output process kortesi torch.Size([32, 458, 51])\n",
            "output process kortesi\n",
            "output process kortesi tensor(19.5070, device='xla:1', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(phone_cache )"
      ],
      "metadata": {
        "id": "hWcsW-oJY781"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FLqOdGW8bxnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}